{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOkQn9KJFWzPp0rzYDhpTdH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rprimi/b5_nlp/blob/main/m2_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tensorflow\")\n",
        "library(tensorflow)\n",
        "install.packages(\"keras\")\n",
        "library(keras)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "install_tensorflow()\n",
        "\n",
        "library(reticulate)\n",
        "use_python(\"/usr/bin/python3\")\n",
        "\n",
        "\n",
        "install_tensorflow(\n",
        "  version = \"default\",\n",
        "  method = c(\"auto\"),\n",
        "  cuda = TRUE,\n",
        " envname = \"NULL\" )\n",
        "\n",
        "install_tensorflow(version = \"default\", cuda = TRUE)\n",
        "\n",
        "install.packages(\"devtools\")\n",
        "devtools::install_github(\"rstudio/reticulate\")\n",
        "install.packages(\"tensorflow\")\n",
        "library(reticulate)\n",
        "use_python(\"/usr/local/lib/python3.10\")\n",
        "\n",
        "dist-packages\n",
        "library(tensorflow)\n",
        "tf_config()\n",
        "\n",
        "py_run_string(\"import tensorflow as tf\")\n",
        "py_run_string(\"print(tf.__version__)\")\n",
        "\n",
        "\n",
        "pacakges <- c(\"tidyverse\", \"keras\", \"psych\", \"readr\", \"zip\")\n",
        "install.packages(pacakges)\n",
        "detach(\"package:tensorflow\")\n",
        "detach\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "zu3HAEog7BsJ",
        "outputId": "8b72ea87-5f46-4668-8bf8-5cb4a3086123"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in use_python(\"/usr/local/lib/python3.10\"): failed to initialize requested version of Python\nTraceback:\n",
            "1. use_python(\"/usr/local/lib/python3.10\")",
            "2. stop(\"failed to initialize requested version of Python\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wMnn2iO95jpK"
      },
      "outputs": [],
      "source": [
        "library(tidyverse)\n",
        "library(keras)\n",
        "library(psych)\n",
        "library(readr)\n",
        "library(zip)\n",
        "\n",
        "# library(tensorflow)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load(\"base_bfi_nlp.RData\")"
      ],
      "metadata": {
        "id": "u179Fq4m8HUe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples <- db_textos_splited$texto_dividido\n",
        "\n",
        "tokenizer <- text_tokenizer(\n",
        "    lower = TRUE )  %>%\n",
        "    fit_text_tokenizer(samples)\n",
        "\n",
        "word_index <- tokenizer$word_index\n",
        "\n",
        "sequences <- texts_to_sequences(tokenizer, samples)\n",
        "\n",
        "cat(\"Found\", length(word_index), \"unique tokens.\\n\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "JpE1zzRI8YIM",
        "outputId": "56aae0d4-4a60-4fed-aa83-04cffecf7eb1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of 22\n",
            " $ python              : chr \"/root/.virtualenvs/r-tensorflow/bin/python\"\n",
            " $ libpython           : chr \"/usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so\"\n",
            " $ pythonhome          : chr \"/root/.virtualenvs/r-tensorflow:/root/.virtualenvs/r-tensorflow\"\n",
            " $ pythonpath          : chr \"/usr/local/lib/R/site-library/reticulate/config:/env/python:/usr/lib/python310.zip:/usr/lib/python3.10:/usr/lib\"| __truncated__\n",
            " $ prefix              : chr \"/root/.virtualenvs/r-tensorflow\"\n",
            " $ exec_prefix         : chr \"/root/.virtualenvs/r-tensorflow\"\n",
            " $ base_exec_prefix    : chr \"/usr\"\n",
            " $ virtualenv          : chr \"/root/.virtualenvs/r-tensorflow\"\n",
            " $ virtualenv_activate : chr \"\"\n",
            " $ executable          : chr \"/root/.virtualenvs/r-tensorflow/bin/python\"\n",
            " $ base_executable     : chr \"/root/.virtualenvs/r-tensorflow/bin/python\"\n",
            " $ version_string      : chr \"3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\"\n",
            " $ version             : chr \"3.10\"\n",
            " $ architecture        : chr \"64bit\"\n",
            " $ anaconda            : logi FALSE\n",
            " $ conda               : chr \"False\"\n",
            " $ numpy               : NULL\n",
            " $ required_module     : chr \"tensorflow\"\n",
            " $ required_module_path: NULL\n",
            " $ available           : logi TRUE\n",
            " $ python_versions     : chr \"/root/.virtualenvs/r-tensorflow/bin/python\"\n",
            " $ forced              : chr \"import(\\\"tensorflow\\\")\"\n",
            " - attr(*, \"class\")= chr \"py_config\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error: Python module tensorflow.keras was not found.\n\nDetected Python configuration:\n\n\n\nTraceback:\n",
            "1. text_tokenizer(lower = TRUE) %>% fit_text_tokenizer(samples)",
            "2. fit_text_tokenizer(., samples)",
            "3. text_tokenizer(lower = TRUE)",
            "4. keras_version()",
            "5. as_r_value(py_get_attr(keras, \"__version__\", TRUE)) %||% tensorflow::tf_config()$version_str",
            "6. as_r_value(py_get_attr(keras, \"__version__\", TRUE))",
            "7. py_get_attr(keras, \"__version__\", TRUE)",
            "8. py_resolve_module_proxy(x)",
            "9. stop(message, call. = FALSE)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load(\"/content/vocabulary.RData\")\n",
        "names(vocabulary)\n",
        "\n",
        "# Function adapted from Chalot book\n",
        "  prepare_embedding_matrix <- function(num_words, EMBEDDING_DIM, word_index) {\n",
        "      MAX_NUM_WORDS = num_words\n",
        "      embedding_matrix <- matrix(0L, nrow = num_words+1, ncol = EMBEDDING_DIM)\n",
        "      for (word in names(word_index)) {\n",
        "        index <- word_index[[word]]\n",
        "        if (index >= MAX_NUM_WORDS)\n",
        "          next\n",
        "        embedding_vector <- as.numeric(vocabulary[vocabulary$word == word, 3:602])\n",
        "        if (!is.null(embedding_vector)) {\n",
        "          # words not found in embedding index will be all-zeros.\n",
        "          embedding_matrix[index+1,] <- embedding_vector\n",
        "        }\n",
        "      }\n",
        "      embedding_matrix\n",
        "    }\n",
        "\n",
        "# Creates embedding matrix\n",
        "     embedding_matrix <- prepare_embedding_matrix(\n",
        "         num_words = 66128,\n",
        "         EMBEDDING_DIM = 600,\n",
        "         word_index = word_index)\n",
        "\n",
        "# Fills empty rows with random number\n",
        "    rnd <- runif(n=sum(is.na(embedding_matrix)), min = 0, max = .04)\n",
        "    embedding_matrix[is.na(embedding_matrix)] <- rnd\n",
        "\n",
        "# Test it\n",
        "   table(is.na(embedding_matrix))\n",
        "\n",
        "# See shape of embedding matrix and first row (needs to be zero, don't know why)\n",
        "# https://github.com/rstudio/keras/issues/302)\n",
        "   dim(embedding_matrix)\n",
        "   embedding_matrix[1, ]\n",
        ""
      ],
      "metadata": {
        "id": "zzM0nd-D-ver"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    hist(map_dbl(sequences, length))\n",
        "\n",
        "# Shuffle data\n",
        "    set.seed(8)\n",
        "\n",
        "    indices <- sample(1:length(sequences))\n",
        "\n",
        "    prop_train <- .82\n",
        "    maxlen <-250\n",
        "\n",
        "    train_indices <- 1: round(prop_train*length(sequences), 0)\n",
        "    test_indices <-  (round(prop_train*length(sequences), 0)+1) : length(sequences)\n",
        "\n",
        "\n",
        "    x_train <- pad_sequences(sequences[indices[train_indices]], maxlen = maxlen)\n",
        "    x_test <- pad_sequences(sequences[indices[test_indices]], maxlen = maxlen)\n",
        "\n",
        "    db_ys <- db_textos_splited[ , \"id\"] %>%\n",
        "      as.data.frame() %>%\n",
        "      set_names(\"id\") %>%\n",
        "      mutate(id = as.numeric(id)) %>%\n",
        "      left_join( {db_bfi %>% select(id, O_rec:N_vlti_rec)}, by = \"id\" )\n",
        "\n",
        "\n",
        "    y_train <- as.matrix(db_ys[indices[train_indices] , 2:6])\n",
        "    y_test <-  as.matrix(db_ys[indices[test_indices] , 2:6])\n",
        "\n",
        "    dim(x_train)\n",
        "    dim(x_test)\n",
        "\n",
        "    dim(y_train)\n",
        "    dim(y_test)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "he6lOChvBH93",
        "outputId": "1cea5079-ddd7-4a75-89f4-2759ea3796f9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>9460</li><li>5</li></ol>\n"
            ],
            "text/markdown": "1. 9460\n2. 5\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 9460\n\\item 5\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 9460    5"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  max_words = 66128\n",
        "    embedding_dim = 600\n",
        "\n",
        "# bidirectional lstm model\n",
        "\n",
        "   model <- keras_model_sequential() %>%\n",
        "     layer_embedding(\n",
        "         input_dim = max_words + 1,\n",
        "         output_dim = embedding_dim ,\n",
        "         weights = list(embedding_matrix),\n",
        "         input_length = maxlen,\n",
        "         trainable = FALSE ) %>%\n",
        "    bidirectional(layer_lstm(units = 64,recurrent_dropout = 0.5, dropout =.5)) %>%\n",
        "    layer_dense(units = 5,  kernel_regularizer = regularizer_l2(0.001))\n",
        "\n",
        "    summary(model)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzIhYyJ0BL4E",
        "outputId": "49a2711b-d4a4-4fca-b43e-eba9bf872aa2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "________________________________________________________________________________\n",
            " Layer (type)                  Output Shape               Param #    Trainable  \n",
            "================================================================================\n",
            " embedding_1 (Embedding)       (None, 250, 600)           39677400   N          \n",
            " bidirectional_1 (Bidirection  (None, 128)                340480     Y          \n",
            " al)                                                                            \n",
            " dense_1 (Dense)               (None, 5)                  645        Y          \n",
            "================================================================================\n",
            "Total params: 40018525 (152.66 MB)\n",
            "Trainable params: 341125 (1.30 MB)\n",
            "Non-trainable params: 39677400 (151.36 MB)\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for continouse y-variable\n",
        "\n",
        "class_callback_loss_history <- new_callback_class(\n",
        "    \"loss_history\",\n",
        "    initialize = function() {\n",
        "      self$batch_losses <- numeric()\n",
        "    },\n",
        "    on_batch_end = function(batch, logs) {\n",
        "      # Append current batch's loss to the list\n",
        "      self$batch_losses <- c(self$batch_losses, logs$get(\"loss\"))\n",
        "\n",
        "      # Plot the losses\n",
        "      df <- data.frame(Batch = 1:length(self$batch_losses), Loss = self$batch_losses)\n",
        "      print(\n",
        "        ggplot(df, aes(x = Batch, y = Loss)) +\n",
        "          geom_line(color = \"blue\") +\n",
        "          labs(title = \"Training Loss per Batch\", x = \"Batch\", y = \"Loss\") +\n",
        "          theme_minimal()\n",
        "      )\n",
        "    }\n",
        ")\n",
        "\n",
        "    model %>% compile(\n",
        "        optimizer = \"rmsprop\",\n",
        "        loss = \"mse\",\n",
        "        metrics = c(\"mae\")\n",
        "    )\n",
        "\n",
        "\n",
        "    history <- model %>% fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      epochs =9,\n",
        "      batch_size = 100,\n",
        "      validation_data = list(x_test, y_test),\n",
        "\n",
        "      callbacks = list(class_callback_loss_history())\n",
        "    )\n",
        "\n",
        "    plot(history)\n"
      ],
      "metadata": {
        "id": "YlJSd0kIBPyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    results <-  model %>% evaluate(x_test, y_test)\n",
        "    predictions <-  model %>% predict(x_test)\n",
        "    results\n",
        "\n",
        "    cbind(predictions, y_test) %>%  corr.test()\n",
        "\n",
        "    ggplot(\n",
        "        data = data.frame(\n",
        "            cbind(y_test, y_pred = predictions[ , 1])\n",
        "            ),\n",
        "        aes(x = y_test, y = y_pred) ) +\n",
        "        geom_point( alpha = 1/2) +\n",
        "        geom_smooth(method = \"lm\") +\n",
        "        geom_smooth(color = \"red\")\n",
        "\n",
        "   resp2[indices[test_indices], ] %>%\n",
        "       cbind(predictions) %>%\n",
        "       select(Código, Ma_measure, y_theta_z, predictions) %>%\n",
        "       group_by(Código) %>%\n",
        "       summarise_all(.funs = mean) %>%\n",
        "       select(-Código) %>%\n",
        "       ggplot(aes(x = Ma_measure, y = predictions) ) +\n",
        "        geom_point( alpha = 1/2) +\n",
        "        geom_smooth(method = \"lm\") +\n",
        "        geom_smooth(color = \"red\")\n",
        "\n",
        "\n",
        "    resp2[indices[test_indices], ] %>%\n",
        "       cbind(predictions) %>%\n",
        "       select(Código, Ma_measure, y_theta_z, predictions) %>%\n",
        "       group_by(Código) %>%\n",
        "       summarise_all(.funs = mean) %>%\n",
        "       select(-Código) %>%\n",
        "       corr.test()\n",
        "\n",
        "\n",
        "    results <- model %>% evaluate(x_train, y_train)\n",
        "    predictions <- model %>% predict(x_train)\n",
        "    cor(predictions, y_train)\n",
        "\n",
        "    ggplot(\n",
        "        data = data.frame(\n",
        "            cbind(y_train, y_pred = predictions[ , 1])\n",
        "            ),\n",
        "        aes(x = y_train, y = y_pred) ) +\n",
        "        geom_point( alpha = 1/2) +\n",
        "        geom_smooth(color = \"orange\") +\n",
        "        geom_smooth(method = \"lm\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fzkQZjTCBU2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}