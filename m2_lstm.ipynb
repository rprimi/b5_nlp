{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNp9fkv4F/Bkg8S8pLaJ2e/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rprimi/b5_nlp/blob/main/m2_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "install.packages(\"devtools\")\n",
        "devtools::install_github(\"rstudio/reticulate\")\n",
        "library(reticulate)\n",
        "use_python(\"/usr/local/lib/python3.10\")\n",
        "\n",
        "\n",
        "install.packages(\"tensorflow\")\n",
        "library(tensorflow)\n",
        "install.packages(\"keras\")\n",
        "library(keras)\n",
        "\n",
        "\n",
        "library(reticulate)\n",
        "use_python(\"/usr/bin/python3\")\n",
        "\n",
        "\n",
        "install_tensorflow(\n",
        "  version = \"default\",\n",
        "  method = c(\"auto\"),\n",
        "  cuda = TRUE,\n",
        " envname = \"NULL\" )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zu3HAEog7BsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wMnn2iO95jpK",
        "outputId": "9bb49137-3fb8-4ac3-f22f-aa2255a20bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow built with CUDA:  TRUE \n",
            "GPU device name:  /device:GPU:0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TRUE"
            ],
            "text/markdown": "TRUE",
            "text/latex": "TRUE",
            "text/plain": [
              "[1] TRUE"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "pacakges <- c(\"tidyverse\", \"keras\", \"psych\", \"readr\", \"zip\")\n",
        "install.packages(pacakges)\n",
        "\n",
        "library(tidyverse)\n",
        "library(keras)\n",
        "library(psych)\n",
        "library(readr)\n",
        "library(zip)\n",
        "\n",
        "\n",
        "tensorflow::tf_version()\n",
        "tensorflow::tf_config()\n",
        "tensorflow::tf_gpu_configured(verbose = TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load(\"base_bfi_nlp.RData\")"
      ],
      "metadata": {
        "id": "u179Fq4m8HUe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples <- db_textos_splited$texto_dividido\n",
        "\n",
        "tokenizer <- text_tokenizer(\n",
        "    lower = TRUE )  %>%\n",
        "    fit_text_tokenizer(samples)\n",
        "\n",
        "word_index <- tokenizer$word_index\n",
        "\n",
        "sequences <- texts_to_sequences(tokenizer, samples)\n",
        "\n",
        "cat(\"Found\", length(word_index), \"unique tokens.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpE1zzRI8YIM",
        "outputId": "e56df642-3658-4ad2-8348-0795671cde2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 66128 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load(\"/content/vocabulary.RData\")\n",
        "names(vocabulary)\n",
        "\n",
        "# Function adapted from Chalot book\n",
        "  prepare_embedding_matrix <- function(num_words, EMBEDDING_DIM, word_index) {\n",
        "      MAX_NUM_WORDS = num_words\n",
        "      embedding_matrix <- matrix(0L, nrow = num_words+1, ncol = EMBEDDING_DIM)\n",
        "      for (word in names(word_index)) {\n",
        "        index <- word_index[[word]]\n",
        "        if (index >= MAX_NUM_WORDS)\n",
        "          next\n",
        "        embedding_vector <- as.numeric(vocabulary[vocabulary$word == word, 3:602])\n",
        "        if (!is.null(embedding_vector)) {\n",
        "          # words not found in embedding index will be all-zeros.\n",
        "          embedding_matrix[index+1,] <- embedding_vector\n",
        "        }\n",
        "      }\n",
        "      embedding_matrix\n",
        "    }\n",
        "\n",
        "# Creates embedding matrix\n",
        "     embedding_matrix <- prepare_embedding_matrix(\n",
        "         num_words = 66128,\n",
        "         EMBEDDING_DIM = 600,\n",
        "         word_index = word_index)\n",
        "\n",
        "# Fills empty rows with random number\n",
        "    rnd <- runif(n=sum(is.na(embedding_matrix)), min = 0, max = .04)\n",
        "    embedding_matrix[is.na(embedding_matrix)] <- rnd\n",
        "\n",
        "# Test it\n",
        "   table(is.na(embedding_matrix))\n",
        "\n",
        "# See shape of embedding matrix and first row (needs to be zero, don't know why)\n",
        "# https://github.com/rstudio/keras/issues/302)\n",
        "   dim(embedding_matrix)\n",
        "   embedding_matrix[1, ]\n"
      ],
      "metadata": {
        "id": "zzM0nd-D-ver"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle data\n",
        "    hist(map_dbl(sequences, length))\n",
        "    set.seed(8)\n",
        "\n",
        "    indices <- sample(1:length(sequences))\n",
        "\n",
        "    prop_train <- .82\n",
        "    maxlen <-250\n",
        "\n",
        "    train_indices <- 1: round(prop_train*length(sequences), 0)\n",
        "    test_indices <-  (round(prop_train*length(sequences), 0)+1) : length(sequences)\n",
        "\n",
        "\n",
        "    x_train <- pad_sequences(sequences[indices[train_indices]], maxlen = maxlen)\n",
        "    x_test <- pad_sequences(sequences[indices[test_indices]], maxlen = maxlen)\n",
        "\n",
        "    db_ys <- db_textos_splited[ , \"id\"] %>%\n",
        "      as.data.frame() %>%\n",
        "      set_names(\"id\") %>%\n",
        "      mutate(id = as.numeric(id)) %>%\n",
        "      left_join( {db_bfi %>% select(id, O_rec:N_vlti_rec)}, by = \"id\" )\n",
        "\n",
        "\n",
        "    y_train <- as.matrix(db_ys[indices[train_indices] , 2:6])\n",
        "    y_test <-  as.matrix(db_ys[indices[test_indices] , 2:6])\n",
        "\n",
        "    dim(x_train)\n",
        "    dim(x_test)\n",
        "\n",
        "    dim(y_train)\n",
        "    dim(y_test)\n"
      ],
      "metadata": {
        "id": "he6lOChvBH93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  max_words = 66128\n",
        "    embedding_dim = 600\n",
        "\n",
        "# bidirectional lstm model\n",
        "\n",
        "   model <- keras_model_sequential() %>%\n",
        "     layer_embedding(\n",
        "         input_dim = max_words + 1,\n",
        "         output_dim = embedding_dim ,\n",
        "         weights = list(embedding_matrix),\n",
        "         input_length = maxlen,\n",
        "         trainable = FALSE ) %>%\n",
        "    bidirectional(layer_lstm(units = 64,recurrent_dropout = 0.5, dropout =.5)) %>%\n",
        "    layer_dense(units = 5,  kernel_regularizer = regularizer_l2(0.001))\n",
        "\n",
        "    summary(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzIhYyJ0BL4E",
        "outputId": "ea8aa37a-4c56-4dfe-952f-f60f04788e8d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "________________________________________________________________________________\n",
            " Layer (type)                  Output Shape               Param #    Trainable  \n",
            "================================================================================\n",
            " embedding (Embedding)         (None, 250, 600)           39677400   N          \n",
            " bidirectional (Bidirectional  (None, 128)                340480     Y          \n",
            " )                                                                              \n",
            " dense (Dense)                 (None, 5)                  645        Y          \n",
            "================================================================================\n",
            "Total params: 40018525 (152.66 MB)\n",
            "Trainable params: 341125 (1.30 MB)\n",
            "Non-trainable params: 39677400 (151.36 MB)\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_callback_loss_history <- new_callback_class(\n",
        "    \"loss_history\",\n",
        "    initialize = function() {\n",
        "      self$batch_losses <- numeric()\n",
        "    },\n",
        "    on_batch_end = function(batch, logs) {\n",
        "      # Append current batch's loss to the list\n",
        "      self$batch_losses <- c(self$batch_losses, logs$get(\"loss\"))\n",
        "\n",
        "      # Plot the losses\n",
        "      df <- data.frame(Batch = 1:length(self$batch_losses), Loss = self$batch_losses)\n",
        "      print(\n",
        "        ggplot(df, aes(x = Batch, y = Loss)) +\n",
        "          geom_line(color = \"blue\") +\n",
        "          labs(title = \"Training Loss per Batch\", x = \"Batch\", y = \"Loss\") +\n",
        "          theme_minimal()\n",
        "      )\n",
        "     }\n",
        "   )\n",
        "\n",
        "   model %>% compile(\n",
        "     optimizer = \"rmsprop\",\n",
        "     loss = \"mse\",\n",
        "     metrics = c(\"mae\")\n",
        "    )\n",
        "\n",
        "\n",
        "    history <- model %>% fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      epochs =5,\n",
        "      batch_size = 200,\n",
        "      validation_data = list(x_test, y_test),\n",
        "      verbose = 1\n",
        "      # callbacks = list(class_callback_loss_history())\n",
        "    )\n",
        "\n",
        "    plot(history)\n"
      ],
      "metadata": {
        "id": "YlJSd0kIBPyK",
        "outputId": "139e9cbc-fc55-41af-fee5-460c86bc62bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Final epoch (plot to see history):\n",
              "    loss: 0.5\n",
              "     mae: 0.5663\n",
              "val_loss: 0.5326\n",
              " val_mae: 0.576 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    results <-  model %>% evaluate(x_test, y_test)\n",
        "    predictions <-  model %>% predict(x_test)\n",
        "\n",
        "    names(predictions)\n",
        "    results\n",
        "    dim(y_test)\n",
        "\n",
        "    bind_cols(predictions, y_test) %>%  psych::corr.test()\n",
        "\n",
        "    ggplot(\n",
        "        data = data.frame(\n",
        "            cbind(y_test, y_pred = predictions[ , 1])\n",
        "            ),\n",
        "        aes(x = y_test, y = y_pred) ) +\n",
        "        geom_point( alpha = 1/2) +\n",
        "        geom_smooth(method = \"lm\") +\n",
        "        geom_smooth(color = \"red\")\n",
        "\n",
        "   resp2[indices[test_indices], ] %>%\n",
        "       cbind(predictions) %>%\n",
        "       select(Código, Ma_measure, y_theta_z, predictions) %>%\n",
        "       group_by(Código) %>%\n",
        "       summarise_all(.funs = mean) %>%\n",
        "       select(-Código) %>%\n",
        "       ggplot(aes(x = Ma_measure, y = predictions) ) +\n",
        "        geom_point( alpha = 1/2) +\n",
        "        geom_smooth(method = \"lm\") +\n",
        "        geom_smooth(color = \"red\")\n",
        "\n",
        "\n",
        "    resp2[indices[test_indices], ] %>%\n",
        "       cbind(predictions) %>%\n",
        "       select(Código, Ma_measure, y_theta_z, predictions) %>%\n",
        "       group_by(Código) %>%\n",
        "       summarise_all(.funs = mean) %>%\n",
        "       select(-Código) %>%\n",
        "       corr.test()\n",
        "\n",
        "\n",
        "    results <- model %>% evaluate(x_train, y_train)\n",
        "    predictions <- model %>% predict(x_train)\n",
        "    cor(predictions, y_train)\n",
        "\n",
        "    ggplot(\n",
        "        data = data.frame(\n",
        "            cbind(y_train, y_pred = predictions[ , 1])\n",
        "            ),\n",
        "        aes(x = y_train, y = y_pred) ) +\n",
        "        geom_point( alpha = 1/2) +\n",
        "        geom_smooth(color = \"orange\") +\n",
        "        geom_smooth(method = \"lm\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fzkQZjTCBU2x",
        "outputId": "54e3373f-3bf9-458e-cacd-602402b8337f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mNew names:\n",
            "\u001b[36m•\u001b[39m `` -> `...1`\n",
            "\u001b[36m•\u001b[39m `` -> `...2`\n",
            "\u001b[36m•\u001b[39m `` -> `...3`\n",
            "\u001b[36m•\u001b[39m `` -> `...4`\n",
            "\u001b[36m•\u001b[39m `` -> `...5`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Call:psych::corr.test(x = .)\n",
              "Correlation matrix \n",
              "       ...1  ...2  ...3  ...4  ...5 O_rec C_rec E_rec A_rec N_rec\n",
              "...1   1.00 -0.15 -0.03 -0.12  0.08  0.02 -0.03 -0.06  0.00 -0.06\n",
              "...2  -0.15  1.00  0.51  0.49 -0.02 -0.03  0.04  0.06  0.02  0.03\n",
              "...3  -0.03  0.51  1.00  0.45  0.11  0.00  0.06  0.09  0.07  0.01\n",
              "...4  -0.12  0.49  0.45  1.00 -0.09 -0.03  0.02  0.03  0.01  0.02\n",
              "...5   0.08 -0.02  0.11 -0.09  1.00  0.01 -0.01  0.01  0.02  0.02\n",
              "O_rec  0.02 -0.03  0.00 -0.03  0.01  1.00  0.07  0.22  0.23 -0.15\n",
              "C_rec -0.03  0.04  0.06  0.02 -0.01  0.07  1.00  0.18  0.18 -0.26\n",
              "E_rec -0.06  0.06  0.09  0.03  0.01  0.22  0.18  1.00  0.20 -0.18\n",
              "A_rec  0.00  0.02  0.07  0.01  0.02  0.23  0.18  0.20  1.00 -0.36\n",
              "N_rec -0.06  0.03  0.01  0.02  0.02 -0.15 -0.26 -0.18 -0.36  1.00\n",
              "Sample Size \n",
              "[1] 2077\n",
              "Probability values (Entries above the diagonal are adjusted for multiple tests.) \n",
              "      ...1 ...2 ...3 ...4 ...5 O_rec C_rec E_rec A_rec N_rec\n",
              "...1  0.00 0.00 1.00 0.00 0.00     1  1.00  0.20  1.00  0.11\n",
              "...2  0.00 0.00 0.00 0.00 1.00     1  1.00  0.08  1.00  1.00\n",
              "...3  0.18 0.00 0.00 0.00 0.00     1  0.13  0.00  0.04  1.00\n",
              "...4  0.00 0.00 0.00 0.00 0.00     1  1.00  1.00  1.00  1.00\n",
              "...5  0.00 0.43 0.00 0.00 0.00     1  1.00  1.00  1.00  1.00\n",
              "O_rec 0.28 0.25 0.95 0.22 0.76     0  0.03  0.00  0.00  0.00\n",
              "C_rec 0.12 0.09 0.01 0.48 0.78     0  0.00  0.00  0.00  0.00\n",
              "E_rec 0.01 0.00 0.00 0.15 0.61     0  0.00  0.00  0.00  0.00\n",
              "A_rec 0.98 0.39 0.00 0.55 0.40     0  0.00  0.00  0.00  0.00\n",
              "N_rec 0.00 0.17 0.64 0.26 0.31     0  0.00  0.00  0.00  0.00\n",
              "\n",
              " To see confidence intervals of the correlations, print with the short=FALSE option"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}